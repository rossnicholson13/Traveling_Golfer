{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import csv\n",
    "import lxml.html as lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of rows: 15526\n"
     ]
    }
   ],
   "source": [
    "filename = \"/Users/rossnicholson/GT_DataScience/Project/Traveling_Golfer/scraper files/ga_place_search.csv\"\n",
    "  \n",
    "# initializing the titles and rows list \n",
    "rows = [] \n",
    "  \n",
    "# reading csv file \n",
    "with open(filename, 'r') as csvfile: \n",
    "    # creating a csv reader object \n",
    "    csvreader = csv.reader(csvfile) \n",
    "      \n",
    "    # extracting field names through first row \n",
    "    # fields = csvreader.next() \n",
    "  \n",
    "    # extracting each data row one by one \n",
    "    for row in csvreader: \n",
    "        rows.append(row) \n",
    "  \n",
    "    # get total number of rows \n",
    "    print(\"Total no. of rows: %d\"%(csvreader.line_num)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'KEY HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_details = pd.DataFrame()\n",
    "\n",
    "for i in range(11476,len(rows)):\n",
    "    params = {\n",
    "        'input': rows[i][0],\n",
    "        'key':api_key,\n",
    "        'inputtype':'textquery'\n",
    "    }\n",
    "    print(i)\n",
    "    req = requests.get(\"https://maps.googleapis.com/maps/api/place/findplacefromtext/json?\", params=params)\n",
    "    res = req.json()\n",
    "    \n",
    "    try:\n",
    "        place_id = res['candidates'][0]['place_id']\n",
    "    except:\n",
    "        place_id = 'N/A'\n",
    "        \n",
    "\n",
    "    temp_dict = {'Place':rows[i][0],\n",
    "                     'Course ID':rows[i][1],\n",
    "                    'Place ID':place_id}\n",
    "\n",
    "    temp_df = pd.DataFrame(temp_dict,[i])\n",
    "    course_details = course_details.append(temp_df)\n",
    "    \n",
    "course_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_details.to_csv('ga_google_place.csv',mode='a',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
